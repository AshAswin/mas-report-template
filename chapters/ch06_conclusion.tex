%!TEX root = ../report.tex

\begin{document}
    \chapter{Conclusions}
	This research work focuses on benchmarking state-of-the-art uncertainty estimation methods in neural networks meant for the task of regression. The intent of this work is to evaluate modern uncertainty estimation methods on various aspects, in order to aid Deep Learning (DL) practitioners choose a suitable method based on their requirements, and also to let the DL research community know potential methods to be considered for enhancements and further research. A survey of methods is conducted to choose the top five state-of-the art methods for further analysis. Based on claims made by authors and deficits analysis, two (MCDO\_ADF and DER) out of five methods are chosen for an intensive experimental evaluation. The chosen pair of methods are evaluated using the openly available Udacity steering angle dataset that corresponds to a safety-critical application and a set of three datasets generated from 1D functions. The selected uncertainty estimation methods are evaluated on: the quality of estimated uncertainty, their impact on predictive accuracies of host models and responses to OOD data inputs. DER integrated models output more accurate predictions and uncertainty estimates of higher quality than the other, while MCDO\_ADF performs desirably in responding to OOD inputs.
	
    \section{Contributions}
	Following is the list of important contributions made by this work:
	\begin{itemize}
		\item Literature review and identification of state-of-the-art uncertainty estimation methods for regression nets.
		\item Extensive description and comparison of MCDO\_ADF and DER approaches, on Udacity steering angle dataset and three synthesized 1D datasets.
		\item Implementation of GP models and comparison with MCDO\_ADF and DER on 1D datasets.
		\item Identification of metrics and detailed analysis of NLL as a measure of uncertainty estimation quality.
		\item Evaluation of responses of uncertainty estimation methods to adversarially perturbed and OOD inputs and its corresponding implementation.
		\item Spearman's rank correlation analysis of uncertainty estimation methods on adversarially perturbed inputs from Udacity steering angle dataset.
	\end{itemize}
    \section{Lessons Learned}
    The following insights were gained during the course of this research work:
    \begin{itemize}
    	\item It is preferred for an uncertainty estimation method to learn how to model uncertainties from training data rather than estimating uncertainty during test-time with some implicit assumptions.
    	\item A hierarchy of distributions can be used to model both the likelihood distribution and distributions over its parameters simultaneously.
    	\item There does not exist a metric  to evaluate fidelity of uncertainty estimation methods, in approximating the exact posterior predictive  distribution, especially in the regression setup. The NLL metric only measures the goodness of fit of ground truth in the predicted distribution.
    	\item It is crucial to evaluate uncertainty estimation methods not only based on metrics but also based on their role in the end application such as selective prediction. 
    	\item It is important for any uncertainty estimation method to consider and model the relationship between epistemic and aleatoric uncertainty components.    	
    \end{itemize}

    \section{Future Work}
    DER has some clear advantages over MCDO\_ADF in aspects such as reduced inference time and learning how to model uncertainties from training data. The former can be further improved by:
    \begin{itemize}
    	\item Experimenting with different choices for the prior distribution over likelihood, such as Normal-Wishart or Log-Normal distributions. A recently published work \enquote{Regression Prior Networks} \cite{malinin2020regression} focuses on a similar approach.
    	\item Using better strategies to distinctively optimize Data-fit and Regularizer terms of the evidential loss function.
    	\item Understanding the notion of evidence (belief mass) in relation to the application at hand, for enhancing interpretability of outputted uncertainty estimates.
    \end{itemize}

    In general, there is a need for devising a metric that can evaluate uncertainty estimation methods in the regression setup, based on their ability to approximate the predictive posterior distribution, unlike NLL. A success in the extension of GP to be used with high-dimensional data such as images, can be a significant breakthrough in addressing the problem of uncertainty estimation.
    	 
    
\end{document}
